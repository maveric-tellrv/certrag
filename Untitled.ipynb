{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ff79d988-72ce-4f5c-99ad-abaab56a9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import HuggingFaceHub\n",
    "from getpass import getpass\n",
    "from langchain.schema import AIMessage,HumanMessage,SystemMessage\n",
    "from langchain import PromptTemplate,LLMChain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "8e0c6b90-5e5a-44a2-b33e-a6106f296240",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN='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'\n",
    "# HUGGINGFACEHUB_API_TOKEN= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "896efa0c-df1f-4935-86f8-b124df5c60a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fde8a0b3-3435-472a-89f0-16f9db2b5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6c67bc7d-d47e-44bd-9da0-c9fc3e01dba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[HUGGINGFACEHUB_API_TOKEN] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ebfccfe6-748c-4d1c-b9ce-fab88c0c8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"google/flan-t5-xxl\"\n",
    "# repo_id = \"meta-llama/Llama-2-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "53a703fc-765f-4a4d-9f71-0d01359eae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Documents/venv/lib64/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "flan_llm = HuggingFaceHub(\n",
    "    repo_id = repo_id,model_kwargs={\"max_lengh\": 500}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4f9ed2fd-dc7f-4e7c-b681-644f8a6dc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flan_process(question):\n",
    "    template = \"{question}\"\n",
    "    prompt = PromptTemplate(template=template,input_variables=[\"question\"])\n",
    "    llm_chain = LLMChain(prompt=prompt,llm=flan_llm)\n",
    "    return llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dcf826bf-3eff-42b8-84a1-3096f7d48457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a prompt:  who is modi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan_reply: narendra modi\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Please enter a prompt: \")\n",
    "flan_reply = flan_process(question)\n",
    "print(f\"flan_reply: {flan_reply}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece4613-9ad3-4c8b-bab1-c0d086807f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.output_parsers import CommaSepratedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b87bd6cd-d020-4066-a48c-983ca0a87ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import  PromptTemplate,LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b5240c1b-a9f5-47dc-8c1b-ccc1472444b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_topic = \"what are tips for {topic}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "912ab6f9-20a3-4e18-8ca8-0243514a6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "            prompt=PromptTemplate.from_template(prompt_topic),\n",
    "            llm=flan_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fba17165-cd88-4339-80a1-eded76eecc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tips for saving money'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\"saving_money\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "01493cb5-a120-463b-8f51-e3d62e932068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "da585b72-b561-4634-ac46-8972d4cc4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "63099a2a-b178-413c-9c3d-0498701a0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"list of planets? Only use one word for each.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d6027c0b-853d-456f-8129-e0ca0deb426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template,input_variables=[],output_parser=output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "31aa3004-6568-4c38-904c-76c0388baa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt,llm=flan_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5deaee67-0a75-466e-8d49-c1f6be75bec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'venus'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7b8f1dc9-da69-424f-9179-29a1649edcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohit/Documents/venv/lib64/python3.11/site-packages/langchain/chains/llm.py:321: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['venus']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict_and_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615194a8-de48-422a-bbfa-0c354947726c",
   "metadata": {},
   "source": [
    "# Simple sequetial chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ed99be31-51bd-44fb-8564-1ae7ae66f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI_API_KEY=\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e9c7ca6e-a655-46ff-a2a0-eb55cab8ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6a1dabb0-290b-4a98-8930-54a585e04a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "36cfd5f3-00bc-4670-ba64-806459cac29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "efb96c12-7d32-4ac7-a5a5-62634f97d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mvalentine's day, valentine's day, valentine's day\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mvalentine's day is a romantic comedy about a man who is a little too smitten with his girlfriend\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "template_one = \"provide three title of movies about {topic}\"\n",
    "prompt_one = ChatPromptTemplate.from_template(template_one)\n",
    "\n",
    "chain_one = LLMChain(llm=flan_llm,prompt=prompt_one)\n",
    "\n",
    "template_two = \"write one sentece  description for each movie in this {list}\"\n",
    "prompt_two = ChatPromptTemplate.from_template(template_two)\n",
    "\n",
    "#chain_two = LLMChain(llm=llm,prompt=prompt_two)\n",
    "chain_two = LLMChain(llm=flan_llm,prompt=prompt_two)\n",
    "\n",
    "final_chain = SimpleSequentialChain(chains=[chain_one,chain_two],verbose=True)\n",
    "\n",
    "result = final_chain.run(\"romance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467b88c-fde0-47bb-addb-a26b278c5016",
   "metadata": {},
   "source": [
    "# SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ccd8ea38-1475-40e5-95db-98b4a0ab03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b7783c23-0876-41d7-ae1a-2f3df0edabf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_template = \"you are a developer. write a program in {language} that does {task}\"\n",
    "code_prompt_template = PromptTemplate(input_variables=[\"language\",\"task\"],template=code_template)\n",
    "code_chain = LLMChain(llm=flan_llm,prompt=code_prompt_template, output_key=\"code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3478aedd-a2d8-4d20-9423-2ac9637cc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_template= \"Explain this {code}\"\n",
    "explain_prompt_template = PromptTemplate(input_variables=[\"code\"],template=explain_template)\n",
    "explain_chain = LLMChain(llm=flan_llm,prompt=explain_prompt_template, output_key=\"explanation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5944917f-9a37-4bbe-b499-8376a33f4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "                chains=[code_chain,explain_chain],\n",
    "                input_variables = [\"language\",\"task\"],\n",
    "                output_variables = [\"code\",\"explanation\"]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1f920a9e-4609-45e6-ae7b-2396d1d8c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = overall_chain({\"language\":\"python\",\"task\":\"function to add two numbers\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e2d95d25-8ba7-44f1-ac61-1361f3d699b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'python', 'task': 'function to add two numbers', 'code': 'a = int(input()) b = int(input()) if a > b: a = b b = a + b print(a)', 'explanation': 'if a > b: a = b b = a + b print(a)'}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3dec0253-1735-40fb-beb4-156cbf094c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = int(input()) b = int(input()) if a > b: a = b b = a + b print(a)\n"
     ]
    }
   ],
   "source": [
    "print(results['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1ec0b-ad65-4e3e-9094-f22b23684d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
